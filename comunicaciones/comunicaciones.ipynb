{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciónes de normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import unicodedata\n",
    "import re\n",
    "from difflib import get_close_matches\n",
    "\n",
    "def normalize_string(s: str, delete_non_letters: bool = False) -> str:\n",
    "    s = str(s)\n",
    "    # Convertir a ASCII, eliminar acentos\n",
    "    s = unicodedata.normalize('NFKD', s).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    \n",
    "    # Eliminar caracteres especiales, dejar solo letras, números y espacios\n",
    "    if delete_non_letters:\n",
    "        s = re.sub(r'[^a-zA-Z0-9\\s]', '', s)\n",
    "    else:\n",
    "        # Si no se eliminan los caracteres no letras, aún podríamos querer eliminar algunos caracteres especiales\n",
    "        s = re.sub(r'[^\\w\\s]', '', s)\n",
    "    \n",
    "    # Convertir a mayúsculas\n",
    "    return s.upper()\n",
    "\n",
    "def get_unsensitive_close_matches(word, possibilities, n=3, cutoff=0.6):\n",
    "    \"\"\"\n",
    "    Encuentra lista de coincidiencias suficientemente buenas\n",
    "    comparando valores normalizados\n",
    "    \"\"\"\n",
    "    normalized_word = normalize_string(word, True).lower()\n",
    "    normalized_possibilities = [normalize_string(str(s), True).lower() for s in possibilities]\n",
    "    close_normalized_matches = get_close_matches(normalized_word, normalized_possibilities, n, cutoff)\n",
    "    close_matches = []\n",
    "    for cnm in close_normalized_matches:\n",
    "        index = normalized_possibilities.index(cnm)\n",
    "        close_matches.append(possibilities[index])\n",
    "    return close_matches\n",
    "\n",
    "def get_closest_match(possibilities: list[str], word: str, default_value = \"\") -> str:\n",
    "    if not word:\n",
    "        return default_value\n",
    "    matches = get_unsensitive_close_matches(word, possibilities, n=5, cutoff=0.7)\n",
    "    return matches[0] if matches else default_value\n",
    "\n",
    "\n",
    "def normalize_json(data):\n",
    "    if isinstance(data, dict):\n",
    "        return {normalize_string(key): normalize_json(value) for key, value in data.items()}\n",
    "    elif isinstance(data, list):\n",
    "        return [normalize_json(item) for item in data]\n",
    "    elif isinstance(data, str):\n",
    "        return normalize_string(data)\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "def find_department(department_cities: dict, city: str) -> str:\n",
    "    if not city:\n",
    "        return \"\"\n",
    "    all_cities = {}\n",
    "    for dept, cities in department_cities.items():\n",
    "        for city in cities:\n",
    "            all_cities[city] = dept\n",
    "    if city:\n",
    "        return all_cities[city]\n",
    "    return \"\"\n",
    "\n",
    "with open(\"utils/ciudades_normalizadas.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    department_cities = json.load(file)\n",
    "\n",
    "def format_place(department_name: str, city_name: str) -> tuple[str, str]:\n",
    "    department_name = str(department_name)\n",
    "    city_name = str(city_name)\n",
    "    if city_name == \"nan\":\n",
    "        city_name = \"\"\n",
    "\n",
    "    if city_name.lower() == \"caqueta\" or city_name.lower() == \"florencia\":\n",
    "        city_name = \"Florencia\"\n",
    "        department_name = \"Caqueta\"\n",
    "\n",
    "    all_cities = {}\n",
    "    for dept, cities in department_cities.items():\n",
    "        for city in cities:\n",
    "            all_cities[city] = dept\n",
    "    city_name_formated = get_closest_match(list(all_cities.keys()), city_name)\n",
    "\n",
    "    departments = list(department_cities.keys())\n",
    "    if \"bogota\" in  normalize_string(city_name).lower():\n",
    "        department_name = get_closest_match(departments, \"bogota dc\")\n",
    "    department_name_formated = get_closest_match(departments, department_name)\n",
    "    if not department_name_formated:\n",
    "        department_name_formated = all_cities.get(city_name_formated, \"\")\n",
    "\n",
    "    return department_name_formated, city_name_formated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizar nombres ciudades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo JSON\n",
    "with open('utils/ciudades.json', 'r', encoding='utf-8') as file:\n",
    "    ciudades = json.load(file)\n",
    "\n",
    "# Normalizar el JSON\n",
    "ciudades_normalizadas = normalize_json(ciudades)\n",
    "\n",
    "# Guardar el JSON normalizado\n",
    "with open('utils/ciudades_normalizadas.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(ciudades_normalizadas, file, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizar nombres en base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "\n",
    "# Nombre del archivo\n",
    "filename = 'datos.xlsx'\n",
    "\n",
    "# Cargar el archivo Excel\n",
    "wb = load_workbook(filename)\n",
    "sheet = wb['TODOS']\n",
    "\n",
    "# Normalizar los valores en la columna 'Nombre'\n",
    "for cell in sheet[\"A\"][1:]:  # Empezamos desde la segunda fila para evitar el encabezado\n",
    "    if cell.value:\n",
    "        cell.value = normalize_string(str(cell.value))\n",
    "\n",
    "# Guardar los cambios sobreescribiendo el archivo original\n",
    "wb.save(\"datos_normalized.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definición de clase para leer hojas de cálculo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "\n",
    "def get_cities()->dict:\n",
    "    with open('utils/ciudades_normalizadas.json', 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "class ExcelDataProcessor:\n",
    "    def __init__(self, filename, sheet_name, nombre_col, correo_col, \n",
    "                 dept_col=None, city_col=None, \n",
    "                 combined_col=None, combined_format=None):\n",
    "        self.filename = filename\n",
    "        self.sheet_name = sheet_name\n",
    "        self.nombre_col = nombre_col\n",
    "        self.correo_col = correo_col\n",
    "        self.dept_col = dept_col\n",
    "        self.city_col = city_col\n",
    "        self.combined_col = combined_col\n",
    "        self.combined_format = combined_format\n",
    "        self.data = None\n",
    "        self.read_excel()\n",
    "\n",
    "    def read_excel(self):\n",
    "        try:\n",
    "            df = pd.read_excel(self.filename, sheet_name=self.sheet_name)\n",
    "            required_columns = [self.nombre_col, self.correo_col]\n",
    "            \n",
    "            if self.combined_col:\n",
    "                required_columns.append(self.combined_col)\n",
    "            if self.dept_col:\n",
    "                required_columns.append(self.dept_col)\n",
    "            if self.city_col:\n",
    "                required_columns.append(self.city_col)\n",
    "            \n",
    "            if not all(col in df.columns for col in required_columns):\n",
    "                missing_cols = [col for col in required_columns if col not in df.columns]\n",
    "                raise ValueError(f\"Columnas faltantes: {', '.join(missing_cols)}\")\n",
    "            \n",
    "            df = df.dropna(subset=[self.correo_col])\n",
    "\n",
    "            self.data = df\n",
    "            self._process_dept_city()\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error al leer el archivo Excel: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def _process_dept_city(self):\n",
    "        self.data['Departamento'] = ''\n",
    "        self.data['Ciudad'] = ''\n",
    "\n",
    "        if self.dept_col and self.city_col:\n",
    "            self.data['Departamento'] = self.data[self.dept_col]\n",
    "            self.data['Ciudad'] = self.data[self.city_col]\n",
    "        elif self.dept_col:\n",
    "            self.data['Departamento'] = self.data[self.dept_col]\n",
    "        elif self.city_col:\n",
    "            self.data['Ciudad'] = self.data[self.city_col]\n",
    "        elif self.combined_col and self.combined_format:\n",
    "            pattern = self.combined_format.replace(\"%dept\", \"(.+?)\").replace(\"%city\", \"(.+?)\")\n",
    "            extracted = self.data[self.combined_col].str.extract(pattern)\n",
    "            if '%dept' in self.combined_format and '%city' in self.combined_format:\n",
    "                self.data['Departamento'] = extracted[0]\n",
    "                self.data['Ciudad'] = extracted[1]\n",
    "            elif '%dept' in self.combined_format:\n",
    "                self.data['Departamento'] = extracted[0]\n",
    "            elif '%city' in self.combined_format:\n",
    "                self.data['Ciudad'] = extracted[0]\n",
    "\n",
    "        self.data = self.data.rename(columns={\n",
    "            self.nombre_col: 'Nombre',\n",
    "            self.correo_col: 'Correo'\n",
    "        })\n",
    "        self.data = self.data[['Nombre', 'Correo', 'Departamento', 'Ciudad']]\n",
    "\n",
    "    def get_data(self):\n",
    "        return self.data\n",
    "\n",
    "    def get_by_column(self, column_name):\n",
    "        if column_name in self.data.columns:\n",
    "            return self.data[column_name].tolist()\n",
    "        else:\n",
    "            print(f\"La columna {column_name} no existe en los datos\")\n",
    "            return []\n",
    "\n",
    "    def get_by_index(self, index):\n",
    "        if 0 <= index < len(self.data):\n",
    "            return self.data.iloc[index].to_dict()\n",
    "        else:\n",
    "            print(f\"Índice {index} fuera de rango\")\n",
    "            return {}\n",
    "    \n",
    "    def normalize(self, format_function):\n",
    "        if not callable(format_function):\n",
    "            raise ValueError(\"format_function debe de ser una función callable\")\n",
    "        \n",
    "        def apply_format(row):\n",
    "            dept, city = format_function(row[\"Departamento\"], row[\"Ciudad\"])\n",
    "            return pd.Series({\"Departamento\": dept, \"Ciudad\": city})\n",
    "        \n",
    "        normalized = self.data.apply(apply_format, axis=1)\n",
    "        self.data[[\"Departamento\", \"Ciudad\"]] = normalized\n",
    "\n",
    "\n",
    "class DataMaster:\n",
    "    def __init__(self, filename: str, sheet_name: str):\n",
    "        self.filename = filename\n",
    "        self.sheet_name = sheet_name\n",
    "        self.data = None\n",
    "        self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        try:\n",
    "            self.data = pd.read_excel(self.filename, sheet_name=self.sheet_name)\n",
    "            required_columns = ['Correo', 'Departamento', 'Ciudad']\n",
    "            if not all(col in self.data.columns for col in required_columns):\n",
    "                missing_cols = [col for col in required_columns if col not in self.data.columns]\n",
    "                raise ValueError(f\"Columnas faltantes: {', '.join(missing_cols)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar los datos: {str(e)}\")\n",
    "\n",
    "    def get_data(self):\n",
    "        return self.data\n",
    "    \n",
    "    def prepare_info_data(self, info):\n",
    "        self.info_data = info.get_data()\n",
    "        self.email_index = [(normalize_string(str(email), delete_non_letters=True), i) \n",
    "                            for i, email in enumerate(self.info_data['Correo'])]\n",
    "        self.name_index = [(normalize_string(str(name), delete_non_letters=True), i) \n",
    "                           for i, name in enumerate(self.info_data['Nombre'])]\n",
    "    \n",
    "    def find_row(self, master_row, col_name: str):\n",
    "        master_col_norm = normalize_string(str(master_row[col_name]), delete_non_letters=True)\n",
    "        if col_name == 'Correo':\n",
    "            index_list = self.email_index\n",
    "        else:  # 'Nombre'\n",
    "            index_list = self.name_index\n",
    "        \n",
    "        for info_col_norm, i in index_list:\n",
    "            if master_col_norm.replace(\" \",\"\") in info_col_norm.replace(\" \",\"\"):\n",
    "                return self.info_data.iloc[i]\n",
    "        return None\n",
    "        \n",
    "    def update_places(self, info):\n",
    "        self.prepare_info_data(info)\n",
    "        mask = self.data['Departamento'].isna() | self.data['Ciudad'].isna()\n",
    "        rows_to_update = self.data[mask]\n",
    "        \n",
    "        for index, row in rows_to_update.iterrows():\n",
    "            info_row = self.find_row(row, \"Correo\")\n",
    "            if info_row is None:\n",
    "                info_row = self.find_row(row, \"Nombre\")\n",
    "            if info_row is not None:\n",
    "                self.data.at[index, \"Departamento\"] = info_row[\"Departamento\"]\n",
    "                self.data.at[index, \"Ciudad\"] = info_row[\"Ciudad\"]\n",
    "\n",
    "    def get_by_column(self, column_name: str):\n",
    "        if column_name in self.data.columns:\n",
    "            return self.data[column_name].tolist()\n",
    "        else:\n",
    "            print(f\"La columna {column_name} no existe en los datos\")\n",
    "            return []\n",
    "\n",
    "    def get_by_index(self, index: int):\n",
    "        if 0 <= index < len(self.data):\n",
    "            return self.data.iloc[index].to_dict()\n",
    "        else:\n",
    "            print(f\"Índice {index} fuera de rango\")\n",
    "            return {}\n",
    "    \n",
    "    def show_nontna(self):\n",
    "        notna = self.data[(self.data[\"Ciudad\"].notna()) | (self.data[\"Departamento\"].notna())]\n",
    "        print(notna)\n",
    "\n",
    "    def save(self):\n",
    "        try:\n",
    "            # Cargar el libro de trabajo existente\n",
    "            book = load_workbook(self.filename)\n",
    "            \n",
    "            # Obtener la hoja existente o crear una nueva si no existe\n",
    "            if self.sheet_name in book.sheetnames:\n",
    "                sheet = book[self.sheet_name]\n",
    "            else:\n",
    "                sheet = book.create_sheet(self.sheet_name)\n",
    "\n",
    "            # Limpiar el contenido existente de la hoja\n",
    "            for row in sheet[sheet.dimensions]:\n",
    "                for cell in row:\n",
    "                    cell.value = None\n",
    "\n",
    "            # Escribir los nuevos datos en la hoja\n",
    "            rows = dataframe_to_rows(self.data, index=False, header=True)\n",
    "            for r_idx, row in enumerate(rows, 1):\n",
    "                for c_idx, value in enumerate(row, 1):\n",
    "                    sheet.cell(row=r_idx, column=c_idx, value=value)\n",
    "\n",
    "            # Guardar los cambios\n",
    "            book.save(self.filename)\n",
    "            \n",
    "            print(f\"Datos actualizados exitosamente en {self.filename}, hoja: {self.sheet_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al guardar los datos: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libros\n",
    "amigos_visibles = \"data/amigos_visibles.xlsx\"\n",
    "construccion = \"data/construccion.xlsx\"\n",
    "afrus = \"data/afrus.xlsx\"\n",
    "donaciones_av = \"data/donaciones_av.xlsx\"\n",
    "connect = \"data/connect.xlsx\"\n",
    "aliados = \"data/aliados.xlsx\"\n",
    "evenbrite = \"data/evenbrite.xlsx\"\n",
    "eag = \"data/eag.xlsx\"\n",
    "empresarios_tv = \"data/talento_visible_empresas.xlsx\"\n",
    "alta_gerencia = \"data/alta_gerencia.xlsx\"\n",
    "lidera = \"data/lidera.xlsx\"\n",
    "otros = \"data/otros.xlsx\"\n",
    "influencers = \"data/influencers.xlsx\"\n",
    "medios_comunicacion = \"data/medios_comunicacion.xlsx\"\n",
    "letras_vanguardia_medellin = \"data/letras_vanguardia_medellin.xlsx\"\n",
    "letras_vanguardia_bogota = \"data/letras_vanguardia_bogota.xlsx\"\n",
    "veni_te_leo = \"data/veni_te_leo.xlsx\"\n",
    "red_manos = \"data/red_manos.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Master\n",
    "data_master = DataMaster(\"datos.xlsx\", \"TODOS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Josue\\Documents\\Trabajo\\Manos Visibles\\COMUNICACIONES_DB\\venv\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:223: UserWarning: Cell E631 is marked as a date but the serial value 3117527666 is outside the limits for dates. The cell will be treated as an error.\n",
      "  warn(msg)\n",
      "c:\\Users\\Josue\\Documents\\Trabajo\\Manos Visibles\\COMUNICACIONES_DB\\venv\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Amigos Visibles\n",
    "databases_1 = [\n",
    "    ExcelDataProcessor(amigos_visibles, \"1.PROVEEDORES\", \"Organización\", \"Correo 1\", city_col=\"Cuidad\"),\n",
    "    ExcelDataProcessor(amigos_visibles, \"2. EQUIPO MV, JUNTA,ASAMBL \", \"Nombre\", \"Correo 1\", city_col=\"Ciudad de residencia\"),\n",
    "    ExcelDataProcessor(amigos_visibles, \"4. ORGANIZACIONES MINGALAB\", \"Nombre de la organización\", \"Correo 1\", city_col=\"Ciudad de residencia\"),\n",
    "    ExcelDataProcessor(amigos_visibles, \"4. PODER PACÍFICO\", \"Nombre\", \"Correo 1\", city_col=\"Ciudad de Residencia\"),\n",
    "    ExcelDataProcessor(amigos_visibles, \"4. ESCUELA GOBIERNO\", \"Nombre\", \"Correo 1\", city_col=\"Ciudad de Residencia\"),\n",
    "    ExcelDataProcessor(amigos_visibles, \"4. ESCUELA ECONOMIA\", \"Nombre\", \"Correo 1\", city_col=\"Ciudad de Residencia\"),\n",
    "    ExcelDataProcessor(amigos_visibles, \"5. POT ÉTNICA MDP, CE,MBA,MERC\", \"Nombre\", \"Correo 1\", city_col=\"Ciudad de Residencia\"),\n",
    "    ExcelDataProcessor(amigos_visibles, \"6. FJCP I Y II\", \"Nombre\", \"Correo 1\", city_col=\"Ciudad de Residencia\"),\n",
    "    ExcelDataProcessor(amigos_visibles, \"6. MIT\", \"Nombre\", \"Correo 1\", city_col=\"Ciudad de Residencia\"),\n",
    "    ExcelDataProcessor(amigos_visibles, \"6. ESCUELA SALUD PUB\", \"Nombre\", \"Correo 1\", city_col=\"Ciudad de Residencia\"),\n",
    "    ExcelDataProcessor(amigos_visibles, \"7. DALE \", \"Nombre\", \"Correo 1\", city_col=\"Ciudad de Residencia\"),\n",
    "    ExcelDataProcessor(amigos_visibles, \"7. MUJERES LIDERES CARTAGENA\", \"Nombre\", \"Correo 1\", city_col=\"Ciudad de Residencia\"),\n",
    "    ExcelDataProcessor(amigos_visibles, \"8. POTENCIA ÉTNICA AUDIOVISUAL\", \"Nombre\", \"Correo 1\", city_col=\"Ciudad de Residencia\"),\n",
    "    ExcelDataProcessor(amigos_visibles, \"8. FOCO\", \"Nombre\", \"Correo 1\", city_col=\"Ciudad de Residencia\"),\n",
    "    ExcelDataProcessor(amigos_visibles, \"8. PMB\", \"Nombre\", \"Correo 1\", city_col=\"Ciudad de Residencia\"),\n",
    "    ExcelDataProcessor(amigos_visibles, \"8. FOCO\", \"Nombre\", \"Correo 1\", city_col=\"Ciudad de Residencia\"),\n",
    "    ExcelDataProcessor(amigos_visibles, \"8. FOCO\", \"Nombre\", \"Correo 1\", city_col=\"Ciudad de Residencia\"),\n",
    "    ExcelDataProcessor(amigos_visibles, \"8. FOCO\", \"Nombre\", \"Correo 1\", city_col=\"Ciudad de Residencia\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Josue\\AppData\\Local\\Temp\\ipykernel_20684\\1165152293.py:155: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'BOLIVAR' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  self.data.at[index, \"Departamento\"] = info_row[\"Departamento\"]\n",
      "C:\\Users\\Josue\\AppData\\Local\\Temp\\ipykernel_20684\\1165152293.py:156: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'TURBACO' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  self.data.at[index, \"Ciudad\"] = info_row[\"Ciudad\"]\n"
     ]
    }
   ],
   "source": [
    "for db in databases_1:\n",
    "    db.normalize(format_place)\n",
    "    data_master.update_places(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Josue\\Documents\\Trabajo\\Manos Visibles\\COMUNICACIONES_DB\\venv\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "c:\\Users\\Josue\\Documents\\Trabajo\\Manos Visibles\\COMUNICACIONES_DB\\venv\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "c:\\Users\\Josue\\Documents\\Trabajo\\Manos Visibles\\COMUNICACIONES_DB\\venv\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "databases_2 = [\n",
    "    ExcelDataProcessor(afrus, \"18-09-2024-Personas-24-11-2023-\", \"Nombre completo\", \"Correo electrónico\", city_col=\"Ciudad\"),\n",
    "    ExcelDataProcessor(donaciones_av, \"Hoja 1\", \"Nombre completo\", \"Correo electrónico\", dept_col=\"Departamento\", city_col=\"Ciudad\"),\n",
    "    ExcelDataProcessor(connect, \"BASE RED MV QUIBDÓ\", \"Nombre completo\", \"Correo\", city_col=\"Municipio de Residencia o atención\"),\n",
    "    ExcelDataProcessor(connect, \"BASE DE TUTORES\", \"NOMBRE \", \"CORREO\", city_col=\"NODO\"),\n",
    "    ExcelDataProcessor(evenbrite, \"Sheet 1\", \"Nombre completo\", \"Correo electrónico de comprador\", city_col=\"Ciudad del comprador\"),\n",
    "    ExcelDataProcessor(empresarios_tv, \"Hoja1\", \"Nombre\", \"Correo\", city_col=\"Ciudad\"),\n",
    "    ExcelDataProcessor(alta_gerencia, \"PARTICIPANTES ESC. ALTA GERENCI\", \"NOMBRES Y APELLIDOS DEL/LA PARTICIPANTE\", \"CORREO ELECTRÓNICO DEL/LA PARTICIPANTE\", dept_col=\"DEPTO DE RESIDENCIA\", city_col=\"CIUDAD O MUNICIPIO DE RESIDENCIA\"),\n",
    "    ExcelDataProcessor(lidera, \"Músicos\", \"Nombre\", \"Correo\", city_col=\"Ciudad\"),\n",
    "    ExcelDataProcessor(lidera, \"Actores Actrices\", \"Nombre\", \"Correo\", city_col=\"Ciudad\"),\n",
    "    ExcelDataProcessor(lidera, \"Cine \", \"Nombre\", \"Correo\", city_col=\"Ciudad\"),\n",
    "    ExcelDataProcessor(lidera, \"Académicos\", \"Nombre\", \"Correo\", city_col=\"Ciudad\"),\n",
    "    ExcelDataProcessor(lidera, \"Artes Visuales\", \"Nombre\", \"Correo\", city_col=\"Ciudad\"),\n",
    "    ExcelDataProcessor(lidera, \"Danza\", \"Nombre\", \"Correo\", city_col=\"Ciudad\"),\n",
    "    ExcelDataProcessor(medios_comunicacion, \"Directores y Periodistas \", \"NOMBRE\", \"DIRECCION\", city_col=\"CIUDAD\"),\n",
    "    ExcelDataProcessor(letras_vanguardia_medellin, \"BASE LETRAS DE VANGUARDIA\", \"Nombre\", \"CORREO ELECTRÓNICO DEL/LA PARTICIPANTE\", dept_col=\"DEPTO DE RESIDENCIA\", city_col=\"CIUDAD O MUNICIPIO DE RESIDENCIA\"),\n",
    "    ExcelDataProcessor(letras_vanguardia_bogota, \"PARTICIPANTES ESCUELA VEC\", \"Nombre\", \"CORREO ELECTRÓNICO DEL/LA PARTICIPANTE\", dept_col=\"DEPTO DE RESIDENCIA\", city_col=\"CIUDAD O MUNICIPIO DE RESIDENCIA\"),\n",
    "    ExcelDataProcessor(veni_te_leo, \"PARTICIPANTES ESCUELA VEC\", \"NOMBRES\", \"CORREO ELECTRÓNICO DEL/LA PARTICIPANTE\", dept_col=\"DEPTO DE RESIDENCIA\", city_col=\"CIUDAD O MUNICIPIO DE RESIDENCIA\"),\n",
    "    ExcelDataProcessor(red_manos, \"BASE COMUNICACIONES PRELIMI (2)\", \"Nombre completo\", \"Correo Electrónico\", dept_col=\"Departamento residencia\", city_col=\"Municipio de residencia\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for db in databases_2:\n",
    "    db.normalize(format_place)\n",
    "    data_master.update_places(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos actualizados exitosamente en datos.xlsx, hoja: TODOS\n"
     ]
    }
   ],
   "source": [
    "#data_master.show_nontna()\n",
    "data_master.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
